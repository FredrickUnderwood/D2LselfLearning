{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## PyTorch库的使用"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 标量对向量求导"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 1., 2., 3.])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(4.0)#生成一个长度为4的张量\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.341419300Z",
     "start_time": "2024-01-01T08:25:15.437282700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "x.requires_grad=True\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.342923600Z",
     "start_time": "2024-01-01T08:26:09.340782300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(14., grad_fn=<DotBackward0>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.dot(x,x)\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.348894100Z",
     "start_time": "2024-01-01T08:26:09.343920200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 2., 4., 6.])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.465171400Z",
     "start_time": "2024-01-01T08:26:09.348894100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1., 1., 1.])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#默认情况下torch会自动累计grad，因此要执行清空操作\n",
    "x.grad.zero_()\n",
    "y=x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.466675Z",
     "start_time": "2024-01-01T08:26:09.462488400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 向量对向量的求导（深度学习不常用）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 2., 4., 6.])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y=x*x\n",
    "y.sum().backward()\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.472356100Z",
     "start_time": "2024-01-01T08:26:09.467676100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 1., 4., 9.])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y=x*x\n",
    "u=y.detach()#之前的y=x*x，detach()后y=x*x具体的张量，不再是一个关于x的表达式\n",
    "z=u*x\n",
    "z.sum().backward()\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.480901Z",
     "start_time": "2024-01-01T08:26:09.473352500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PyTorch库中的一些函数的用法"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1034,  0.7309,  0.0063, -2.3537, -1.1998],\n        [ 1.0343,  1.1546,  0.5624,  0.3569,  1.1850],\n        [ 0.2525, -0.4246,  1.7426,  1.0865, -0.3779],\n        [ 1.1537, -0.2080, -0.0221,  0.1396,  0.2900],\n        [ 0.2543,  0.0942,  0.4283,  0.2053, -0.9455]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.normal(mean=0,std=1,size=(5,5))#生成一个五行五列的以0为均值，1为标准差的张量\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.543764600Z",
     "start_time": "2024-01-01T08:26:09.478907800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-2.7452],\n        [-0.4819],\n        [ 0.7484],\n        [ 0.0486],\n        [ 0.2301]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=torch.normal(0,1,(5,1))\n",
    "b=1\n",
    "y=torch.matmul(x,w)+b#矩阵乘法\n",
    "y\n",
    "y=x@w\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.544761300Z",
     "start_time": "2024-01-01T08:26:09.486304200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7452],\n",
      "        [-0.4819],\n",
      "        [ 0.7484],\n",
      "        [ 0.0486],\n",
      "        [ 0.2301]])\n",
      "tensor([[-2.7452, -0.4819,  0.7484,  0.0486,  0.2301]])\n",
      "5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y.reshape(-1,1))#重构为一列\n",
    "print(y.reshape(1,-1))#重构为一行\n",
    "print(len(y.reshape(-1,1)))\n",
    "print(len(y.reshape(1,-1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.545758200Z",
     "start_time": "2024-01-01T08:26:09.492429500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 9]])\n",
      "tensor([[ 6],\n",
      "        [15]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(a.sum(0,keepdim=True))\n",
    "print(a.sum(1,keepdim=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.545758200Z",
     "start_time": "2024-01-01T08:26:09.499413200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14, 32],\n",
      "        [32, 77]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(torch.matmul(a,a.T))#做常规的矩阵乘法"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.546754900Z",
     "start_time": "2024-01-01T08:26:09.502557100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 10])\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "W=torch.normal(0,0.01,size=(784,10),requires_grad=True)\n",
    "print(W.shape)\n",
    "print(W.shape[0])#返回的是第0维的shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.547751900Z",
     "start_time": "2024-01-01T08:26:09.505850Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 2])\n",
      "tensor([1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,2,3],\n",
    "                [3,7,1],\n",
    "                [2,1,3]])\n",
    "print(a.argmax(axis=1))\n",
    "print(a.argmax(axis=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.555278700Z",
     "start_time": "2024-01-01T08:26:09.509391Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[1, 0, 3],\n",
      "        [0, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,-2,3],\n",
    "                [-4,5,6]])\n",
    "print(torch.zeros_like(a))\n",
    "print(torch.max(a,torch.zeros_like(a)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.555278700Z",
     "start_time": "2024-01-01T08:26:09.513166700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "true_w = np.zeros(20)  # 分配大量的空间\n",
    "true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])\n",
    "features = np.random.normal(size=(100 + 100, 1))\n",
    "np.random.shuffle(features)\n",
    "poly_features = np.power(features, np.arange(20).reshape(1, -1))#扩展为features行，20列数组\n",
    "labels = np.dot(poly_features, true_w)\n",
    "print(np.dot(poly_features, true_w).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.556275200Z",
     "start_time": "2024-01-01T08:26:09.517640100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6],\n",
      "        [4, 5, 6, 7, 8, 9]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,2,3],\n",
    "                [4,5,6]])\n",
    "b=torch.tensor([[4,5,6],\n",
    "               [7,8,9]])\n",
    "print(torch.cat((a,b),1))\n",
    "print(torch.cat((a,b),0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.557271900Z",
     "start_time": "2024-01-01T08:26:09.528026300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5000, 3.0000, 4.1000])\n",
      "tensor([2.0667, 3.6667])\n",
      "tensor([[1.5000, 3.0000, 4.1000]])\n",
      "tensor([[2.0667],\n",
      "        [3.6667]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[1,2,3.2],\n",
    "                  [2,4,5]])\n",
    "print(x.mean(dim=0))\n",
    "print(x.mean(dim=1))\n",
    "print(x.mean(dim=0, keepdim=True))\n",
    "print(x.mean(dim=1, keepdim=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.557271900Z",
     "start_time": "2024-01-01T08:26:09.533201400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1528, -1.9216, -1.2357,  0.0783],\n",
      "         [-0.3065,  0.9853,  0.6858,  1.4513],\n",
      "         [ 0.6064, -0.3368,  0.0309,  0.4234]],\n",
      "\n",
      "        [[-2.0129, -0.1707,  2.4639, -0.5384],\n",
      "         [ 0.1817, -0.4872, -0.0934, -0.1570],\n",
      "         [ 0.2110,  0.0046,  1.7948,  0.3049]]])\n",
      "tensor([[[-0.2730],\n",
      "         [ 0.2825],\n",
      "         [ 0.3799]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=(2,3,4))\n",
    "print(x)\n",
    "print(x.mean(dim=(0,2), keepdim=True)) # 那个维度不在求均值的dim中，就保留那个维度的特征"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.557271900Z",
     "start_time": "2024-01-01T08:26:09.538402900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3]]), tensor([[2, 3, 4],\n",
      "        [2, 3, 4],\n",
      "        [2, 3, 4]]))\n",
      "tensor([[1, 1],\n",
      "        [2, 2],\n",
      "        [3, 3]]) tensor([[2, 3],\n",
      "        [2, 3],\n",
      "        [2, 3]])\n",
      "tensor([1, 1, 2, 2, 3, 3]) tensor([2, 3, 2, 3, 2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\33143\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "from torch import meshgrid\n",
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([2, 3, 4])\n",
    "print(meshgrid([a, b]))\n",
    "b = torch.tensor([2, 3])\n",
    "x, y =meshgrid([a, b])\n",
    "print(x, y)\n",
    "print(x.reshape(-1), y.reshape(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.568056700Z",
     "start_time": "2024-01-01T08:26:09.544761300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [3, 4]])\n",
      "tensor([[1, 1, 1, 1, 2, 2, 2, 2],\n",
      "        [3, 3, 3, 3, 4, 4, 4, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "from torch import repeat_interleave\n",
    "import torch\n",
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "print(repeat_interleave(a, 2, dim=0))\n",
    "print(repeat_interleave(a, 4, dim=1))\n",
    "print(a.repeat(3, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.569056300Z",
     "start_time": "2024-01-01T08:26:09.550630100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n",
      "tensor([[1, 3],\n",
      "        [2, 4],\n",
      "        [3, 5]])\n",
      "tensor([[1, 3],\n",
      "        [2, 4],\n",
      "        [3, 5]])\n"
     ]
    }
   ],
   "source": [
    "from torch import stack\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([3, 4, 5])\n",
    "print(stack((a, b)))\n",
    "print(stack((a, b)).T)\n",
    "print(stack((a, b), dim=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.741414200Z",
     "start_time": "2024-01-01T08:26:09.557271900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[[2, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n",
      "torch.return_types.max(\n",
      "values=tensor([4, 5, 6]),\n",
      "indices=tensor([1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 2, 3],\n",
    "                 [4, 5, 6]])\n",
    "b = torch.tensor([[2, 2, 3],\n",
    "                  [4, 3, 6]])\n",
    "c = torch.tensor([2, 1 ,0])\n",
    "\n",
    "print(torch.max(a, b))\n",
    "print(torch.max(a[:, None, :], c))\n",
    "print(torch.max(a, dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.743491400Z",
     "start_time": "2024-01-01T08:26:09.560437300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([3, 3, 1, 2])\n",
    "print((a - b).clamp(min=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.744490200Z",
     "start_time": "2024-01-01T08:26:09.570053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, -1,  2,  0])\n",
      "tensor([[ 1],\n",
      "        [-1],\n",
      "        [ 2],\n",
      "        [ 0]])\n",
      "tensor([[ 1,  1,  1,  1],\n",
      "        [-1, -1, -1, -1],\n",
      "        [ 2,  2,  2,  2],\n",
      "        [ 0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.tensor([1, -1 , 2, 0]))\n",
    "print(torch.tensor([1, -1 , 2, 0]).unsqueeze(-1))\n",
    "print(torch.tensor([1, -1 , 2, 0]).unsqueeze(-1).repeat(1, 4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.744490200Z",
     "start_time": "2024-01-01T08:26:09.574827900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [1, 1],\n",
      "        [1, 2]])\n",
      "tensor([[0, 0],\n",
      "        [0, 1],\n",
      "        [0, 2],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [0, -1, -2]])\n",
    "print(torch.nonzero(a))\n",
    "print(torch.nonzero(a >= 0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.745435200Z",
     "start_time": "2024-01-01T08:26:09.579842800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "print(a[:2].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.745435200Z",
     "start_time": "2024-01-01T08:26:09.585905400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2673, 0.5345, 0.8018],\n",
      "        [0.4558, 0.5698, 0.6838],\n",
      "        [0.5026, 0.5744, 0.6462]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 创建一个示例张量\n",
    "tensor = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                       [4.0, 5.0, 6.0],\n",
    "                       [7.0, 8.0, 9.0]])\n",
    "\n",
    "# 为了对每一行进行归一化，我们先转置，然后用F.normalize进行列归一化，最后再次转置回来\n",
    "normalized_tensor = F.normalize(tensor.T, p=2, dim=0).T\n",
    "\n",
    "print(normalized_tensor)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.745435200Z",
     "start_time": "2024-01-01T08:26:09.590015900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "[3, 3, 3]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "l = [a, a, a]\n",
    "pre = torch.stack(l, dim=0)\n",
    "label = pre.argmax(dim=-1).numpy()\n",
    "ll = list(label)\n",
    "ll"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:09.750443500Z",
     "start_time": "2024-01-01T08:26:09.596001300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[device(type='cuda', index=0)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-30-dc74c42afd39>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mmodel1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtimm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'resnext50_32x4d'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpretrained\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mmodel1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataParallel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mDEVICES\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDEVICES\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mnames\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnamed_parameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnames\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from torch import nn\n",
    "import torch\n",
    "import torchvision\n",
    "DEVICES = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "print(DEVICES)\n",
    "model1 = timm.create_model('resnext50_32x4d', pretrained=False)\n",
    "model1 = nn.DataParallel(model1, device_ids=DEVICES).to(DEVICES[0])\n",
    "names, params = model1.named_parameters()\n",
    "print(names[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T08:26:16.568833900Z",
     "start_time": "2024-01-01T08:26:09.600567500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "a = torch.tensor([1., 2, 3, 4])\n",
    "b = torch.tensor([2., 1, 8, 4])\n",
    "print(F.binary_cross_entropy_with_logits(a, b, reduction='none'))\n",
    "print(a * b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T08:26:16.569830400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"计算二维互相关运算\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y\n",
    "def multi(X, K):\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))\n",
    "X = [torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])]\n",
    "K = [torch.tensor([[0.0, 1.0], [2.0, 3.0]])]\n",
    "for k in K:\n",
    "    print(k)\n",
    "    print(multi(X, K))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-01T08:26:16.570826700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
