{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 神经网络基础"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义层和块（网络结构）\n",
    "在初始化函数中定义每一层神经元的数量等，在forward函数中定义神经网络输出的内容"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "X = torch.rand(2,20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.227660800Z",
     "start_time": "2023-08-01T02:50:51.341129800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 重写MLP的网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0468,  0.1350,  0.0570,  0.2616,  0.1164, -0.0231,  0.0667,  0.2544,\n          0.0185, -0.1810],\n        [ 0.0335,  0.0357,  0.0334,  0.1683,  0.0340,  0.0354,  0.0584,  0.1771,\n          0.0813, -0.1401]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256,10)\n",
    "\n",
    "    # 定义前向传播，即根据输入返回所需的输出\n",
    "    def forward(self,X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "net = MLP()\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.246393100Z",
     "start_time": "2023-08-01T02:50:52.228663400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 重写Sequential类"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.2362, -0.0195,  0.1334,  0.0960, -0.0244,  0.0111, -0.1068, -0.0065,\n         -0.0518, -0.1880],\n        [ 0.1135,  0.0211,  0.1115,  0.1864, -0.1322,  0.0163, -0.0921, -0.0505,\n         -0.0308, -0.1032]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self,*args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block]=block\n",
    "\n",
    "    def forward(self,X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "net = MySequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.251460300Z",
     "start_time": "2023-08-01T02:50:52.246393100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 前向传播的过程中执行代码\n",
    "有时我们希望既不是上一层的结果，但不更新参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.3212, grad_fn=<SumBackward0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand(size = (20,20),requires_grad = False)\n",
    "        self.linear = nn.Linear(20,20)\n",
    "    def forward(self,X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.matmul(X,self.rand_weight))\n",
    "        X = self.linear(X)\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.291083200Z",
     "start_time": "2023-08-01T02:50:52.253974700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 拼接多个组合块"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1704, grad_fn=<SumBackward0>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20,64),nn.ReLU(),\n",
    "                                 nn.Linear(64,32),nn.ReLU())\n",
    "        self.linear = nn.Linear(32,16)\n",
    "    def forward(self,X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "net = nn.Sequential(NestMLP(),nn.Linear(16,20),FixedHiddenMLP())\n",
    "net(X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.291083200Z",
     "start_time": "2023-08-01T02:50:52.264204800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 参数管理（访问训练后的参数）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0852],\n        [-0.0385]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "X = torch.rand(2,4)\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.291083200Z",
     "start_time": "2023-08-01T02:50:52.284835200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.4666,  0.4631,  0.0953, -0.0285],\n",
      "        [-0.0588,  0.4606, -0.3934,  0.4122],\n",
      "        [-0.3251,  0.2309, -0.3357,  0.4679],\n",
      "        [ 0.1092, -0.1846, -0.0482,  0.2321],\n",
      "        [ 0.1629, -0.1277,  0.4303, -0.0567],\n",
      "        [ 0.0293, -0.1303, -0.0661,  0.1289],\n",
      "        [-0.3986,  0.0480, -0.1049,  0.1756],\n",
      "        [ 0.1980, -0.3045,  0.4725,  0.3052]])), ('bias', tensor([ 0.1411,  0.0306, -0.0870, -0.0161, -0.4630, -0.3911, -0.2716,  0.3621]))])\n",
      "OrderedDict()\n",
      "OrderedDict([('weight', tensor([[ 0.2233,  0.0248, -0.1935, -0.1530,  0.1348, -0.0230, -0.0702,  0.0529]])), ('bias', tensor([-0.1751]))])\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.1751], requires_grad=True)\n",
      "tensor([-0.1751])\n"
     ]
    }
   ],
   "source": [
    "print(net[0].state_dict()) # nn.Linear(4,8)\n",
    "print(net[1].state_dict()) # ReLU\n",
    "print(net[2].state_dict()) # nn.Linear(8,1)\n",
    "\n",
    "print(type(net[2].bias)) # nn.parameter\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.291083200Z",
     "start_time": "2023-08-01T02:50:52.284835200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name,param.shape) for name,param in net.named_parameters()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.291083200Z",
     "start_time": "2023-08-01T02:50:52.284835200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2233,  0.0248, -0.1935, -0.1530,  0.1348, -0.0230, -0.0702,  0.0529]])\n",
      "tensor([-0.1751])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()['2.weight'])\n",
    "print(net.state_dict()['2.bias'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.291083200Z",
     "start_time": "2023-08-01T02:50:52.284835200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,4))\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block{i}',block1()) # 使用add_module添加块可以多传入一个字符串\n",
    "    return net\n",
    "\n",
    "net = nn.Sequential(block2(),nn.Linear(4,1))\n",
    "net(X)\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.291083200Z",
     "start_time": "2023-08-01T02:50:52.284835200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 内置的参数初始化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0087,  0.0008,  0.0091,  0.0051],\n",
      "        [ 0.0019, -0.0139, -0.0066, -0.0035],\n",
      "        [ 0.0011,  0.0104, -0.0037,  0.0029],\n",
      "        [-0.0032, -0.0047,  0.0210, -0.0259],\n",
      "        [ 0.0061,  0.0096, -0.0032, -0.0061],\n",
      "        [-0.0037, -0.0213,  0.0070, -0.0056],\n",
      "        [ 0.0016, -0.0175, -0.0088,  0.0037],\n",
      "        [ 0.0140,  0.0014, -0.0042, -0.0096]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "X = torch.rand(2,4)\n",
    "net(X)\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.normal_(m.weight,0,0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "print(net[0].weight.data)\n",
    "print(net[0].bias.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.301822400Z",
     "start_time": "2023-08-01T02:50:52.291083200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.constant_(m.weight,1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)\n",
    "print(net[0].weight.data)\n",
    "print(net[0].bias.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.309638800Z",
     "start_time": "2023-08-01T02:50:52.297257500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4882,  0.1259, -0.5352, -0.1371],\n",
      "        [-0.3418, -0.2946, -0.2709,  0.6576],\n",
      "        [-0.3005,  0.4317,  0.1917,  0.3482],\n",
      "        [ 0.2430, -0.1666, -0.0173,  0.5004],\n",
      "        [-0.4137, -0.5417,  0.6387,  0.1514],\n",
      "        [-0.6126,  0.5526, -0.3399, -0.4946],\n",
      "        [-0.6226,  0.0560, -0.5855, -0.6663],\n",
      "        [-0.3859, -0.5384,  0.2074,  0.2177]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "def xavier(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net[0].apply(xavier)\n",
    "net[2].apply(init_constant)\n",
    "print(net[0].weight.data)\n",
    "print(net[2].weight.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.309638800Z",
     "start_time": "2023-08-01T02:50:52.301822400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 参数绑定\n",
    "参数相同的层"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1468e-01, -1.6295e-01,  4.9518e-01,  2.2858e-01],\n",
      "        [ 2.3199e-01, -4.9075e-01,  4.6173e-01, -4.5443e-01],\n",
      "        [ 4.8810e-01, -3.2350e-01, -1.3084e-01, -1.6645e-01],\n",
      "        [ 4.9488e-01, -9.7150e-03,  1.6348e-01,  1.8681e-01],\n",
      "        [-2.2781e-01, -4.7428e-01, -3.2466e-01, -4.7266e-04],\n",
      "        [-3.7827e-01,  1.2379e-01, -2.1483e-01,  4.1587e-01],\n",
      "        [-4.6888e-01, -4.4578e-01,  3.5723e-01, -2.0310e-01],\n",
      "        [-4.6932e-02,  4.5746e-01,  3.8862e-02, -1.1697e-01]])\n",
      "tensor([[-0.1737,  0.2253, -0.0538, -0.0835,  0.2945,  0.0411,  0.1312,  0.0864],\n",
      "        [-0.1007, -0.2565, -0.3530, -0.3224,  0.2491,  0.2178, -0.1826,  0.1203],\n",
      "        [ 0.0421,  0.1853, -0.1971,  0.1485, -0.3108,  0.0636,  0.1847,  0.1569],\n",
      "        [ 0.3392, -0.2471, -0.0890,  0.3084, -0.2615, -0.2535, -0.1763,  0.0169],\n",
      "        [-0.2217,  0.0794,  0.0474, -0.1461,  0.2627,  0.2565, -0.1689, -0.0934],\n",
      "        [-0.3140,  0.1710, -0.0690, -0.1361,  0.1246,  0.3181, -0.2736,  0.2824],\n",
      "        [ 0.2449, -0.0262,  0.0126,  0.1484,  0.3219, -0.1126,  0.0563,  0.0222],\n",
      "        [-0.2556,  0.1394, -0.1468,  0.3211, -0.2778, -0.0892, -0.1970,  0.0885]])\n",
      "tensor([[-0.1737,  0.2253, -0.0538, -0.0835,  0.2945,  0.0411,  0.1312,  0.0864],\n",
      "        [-0.1007, -0.2565, -0.3530, -0.3224,  0.2491,  0.2178, -0.1826,  0.1203],\n",
      "        [ 0.0421,  0.1853, -0.1971,  0.1485, -0.3108,  0.0636,  0.1847,  0.1569],\n",
      "        [ 0.3392, -0.2471, -0.0890,  0.3084, -0.2615, -0.2535, -0.1763,  0.0169],\n",
      "        [-0.2217,  0.0794,  0.0474, -0.1461,  0.2627,  0.2565, -0.1689, -0.0934],\n",
      "        [-0.3140,  0.1710, -0.0690, -0.1361,  0.1246,  0.3181, -0.2736,  0.2824],\n",
      "        [ 0.2449, -0.0262,  0.0126,  0.1484,  0.3219, -0.1126,  0.0563,  0.0222],\n",
      "        [-0.2556,  0.1394, -0.1468,  0.3211, -0.2778, -0.0892, -0.1970,  0.0885]])\n"
     ]
    }
   ],
   "source": [
    "shared = nn.Linear(8,8)\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),shared,nn.ReLU(),shared,nn.ReLU(),nn.Linear(8,1))\n",
    "print(net[0].weight.data)\n",
    "print(net[2].weight.data)\n",
    "print(net[4].weight.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.311152Z",
     "start_time": "2023-08-01T02:50:52.305521300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 参数的存储"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2702, -0.0776,  0.1907, -0.2793, -0.1714, -0.0742, -0.2040, -0.1597,\n          0.0545,  0.0096],\n        [-0.3035, -0.0950,  0.1523, -0.2274, -0.2713, -0.1258, -0.0129, -0.1498,\n         -0.0074,  0.2829]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256,10)\n",
    "    def forward(self,X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.rand(size=(2,20))\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.314410Z",
     "start_time": "2023-08-01T02:50:52.311152Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "MLP(\n  (hidden): Linear(in_features=20, out_features=256, bias=True)\n  (out): Linear(in_features=256, out_features=10, bias=True)\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(net.state_dict(),'MLP_params')\n",
    "\n",
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('MLP_params'))\n",
    "clone.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.395557800Z",
     "start_time": "2023-08-01T02:50:52.314410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.2702, -0.0776,  0.1907, -0.2793, -0.1714, -0.0742, -0.2040, -0.1597,\n          0.0545,  0.0096],\n        [-0.3035, -0.0950,  0.1523, -0.2274, -0.2713, -0.1258, -0.0129, -0.1498,\n         -0.0074,  0.2829]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone1 = clone(X)\n",
    "clone1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:52.395557800Z",
     "start_time": "2023-08-01T02:50:52.325771600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import My_utils\n",
    "from torch import nn\n",
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:53.108272900Z",
     "start_time": "2023-08-01T02:50:52.329054800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2, 3], device='cuda:0')"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3],device=My_utils.try_gpu())\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:53.154388300Z",
     "start_time": "2023-08-01T02:50:53.108272900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0170],\n        [-0.0352]], device='cuda:0', grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4,1))\n",
    "X = torch.rand(size=(2,4),device=My_utils.try_gpu())\n",
    "net = net.to(device=My_utils.try_gpu())\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T02:50:54.601348Z",
     "start_time": "2023-08-01T02:50:53.154388300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
