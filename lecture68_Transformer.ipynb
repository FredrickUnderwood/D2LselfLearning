{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Attention Is All You Need\n",
    "https://nn.labml.ai/transformers/index.html\n",
    "1. multi-head attention https://nn.labml.ai/transformers/mha.html\n",
    "2. encoder and decoder https://nn.labml.ai/transformers/models.htmlch\n",
    "3. feed forward network https://nn.labml.ai/transformers/feed_forward.html\n",
    "### 自注意力机制 Scaled Dot-Product Attention\n",
    "查询（Query）、键（Key）和值（Value）\n",
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) \\times V\n",
    "$$\n",
    "a (query) Q: n * d_k (d_k: dimension of key)\n",
    "a set of (key-value) set: value前的参数取决于key和query的相似度 K: m * d_k; V: m * d_v (d_v: dimension of value)\n",
    "an (output)： a weighted sum of the values; output: n * d_v\n",
    "Q与K做内积，内积越大，相似度越高；内积为0，则是正交向量，相似度低\n",
    "#### 为什么除以sqrt(d_k)？\n",
    "如果d_k过大，可能导致对应的QK^T过大，导致softmax后的数据过于集中，因此会过早收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### multi-head attention\n",
    "#### 多头注意力机制的引入\n",
    "时序神经网络不能进行并行计算，因此计算的性能很差\n",
    "为了解决这些问题，有ConvS2S这种用卷积神经网络代替的方法，但是卷积神经网络的input和output位置是随机的，难以学习一张图上距离较远的两个位置之间的关系\n",
    "因此引入Transformer的多头注意力机制\n",
    "#### 多头注意力机制\n",
    "1.先定义一个head的个数h\n",
    "2.V、K、Q先各通过一个Linear网络投影到低维（这个Linear网络有参数w可以学习）\n",
    "d_k = d_v = d_model / h\n",
    "3.h组低维的V、K、Q进入Scaled Dot-Product Attention\n",
    "4.将结果concat\n",
    "5.进入一个Linear网络后输出（这个Linear网络有参数w可以学习）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### encoder and decoder\n",
    "#### 编码器和解码器的结构\n",
    "编码器：(x1, x2, ... , xn) -> (z1, z2, ... , zn) 连续生成\n",
    "解码器：(z1, z2, ... , zn) -> (y1, y2, ... , ym) 一个一个生成，输出vector的长度不同\n",
    "解码器的auto_regressive：(z1, z2, ... , zn)先生成y1，之后(z1, z2, ... , zn)和y1生成y2，(z1, z2, ... , zn)再和(y1, y2)生成y3，以此类推。因此过去时刻的输出会成为你当前时刻的输入\n",
    "#### encoder\n",
    "sub-layer1: multi-head attention\n",
    "sub-layer2: feed forward\n",
    "每个sub-layer后增加一个residual层和一个layer-normalization层\n",
    "LayerNorm(x + SubLayer(x))\n",
    "每一个层输出的维度d_model = 512（feature的维度）\n",
    "#### why layer-normalization not batch-normalization?\n",
    "batch-normalization对每个batch的每个feature做均值和方差\n",
    "layer-normalization对每个样本做均值和方差\n",
    "对于数据整体有三个维度，batch_size，seq，feature，因为每个seq的长度可能不同\n",
    "如果对每个feature求均值和方差，每个feature对应不同的seq的长度不同\n",
    "#### decoder\n",
    "sub-layer1: masked multi-head attention \n",
    "masked multi-head attention 防止output在i后面的序列影响i的预测\n",
    "sub-layer2: multi-head attention\n",
    "sub-layer3: feed forward\n",
    "每个sub-layer后增加一个residual层和一个layer-normalization层\n",
    "#### positional encoding\n",
    "如何让自注意力机制使用seq的时序\n",
    "input进入模型的第一步是input embedding层，将input的tokens转换为d_model长度的向量\n",
    "但是这些向量并不具有时序信息\n",
    "positional encoding层通过一个cos和一个sin函数为每个position编号了\n",
    "将编号信息与通过了input embedding层的embedding相加，得到的还是d_model长度的向量，但该向量就具备了时序信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### feed forward network\n",
    "#### 前馈神经网络\n",
    "position-wise fully connected feed forward network 其实就是一个简单的MLP \n",
    "具体来说就是1个Linear层 + 一层ReLU + 一个Linear层 因此就是一个单隐藏层的MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE - ViT\n",
    "https://nn.labml.ai/transformers/vit/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
