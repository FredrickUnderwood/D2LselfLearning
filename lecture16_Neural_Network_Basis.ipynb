{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 神经网络基础"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 自定义层和块（网络结构）\n",
    "在初始化函数中定义每一层神经元的数量等，在forward函数中定义神经网络输出的内容"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "X = torch.rand(2,20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.747532Z",
     "start_time": "2023-07-31T05:32:31.761013500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 重写MLP的网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1453, -0.1370,  0.1046, -0.2033,  0.1468, -0.1944,  0.1545, -0.1770,\n          0.0692,  0.1076],\n        [ 0.1695, -0.1748, -0.1046, -0.1091,  0.2038, -0.2719,  0.1860,  0.0338,\n          0.0705,  0.1264]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256,10)\n",
    "\n",
    "    # 定义前向传播，即根据输入返回所需的输出\n",
    "    def forward(self,X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "net = MLP()\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.753926800Z",
     "start_time": "2023-07-31T05:32:32.747532Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 重写Sequential类"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.1137,  0.1248,  0.3415,  0.0520,  0.3365, -0.3136, -0.1970, -0.0303,\n          0.1339,  0.1484],\n        [ 0.0056, -0.0905,  0.2684,  0.3070,  0.0762, -0.1726, -0.0422,  0.1170,\n          0.1037,  0.1673]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self,*args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block]=block\n",
    "\n",
    "    def forward(self,X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "net = MySequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.758485900Z",
     "start_time": "2023-07-31T05:32:32.753926800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 前向传播的过程中执行代码\n",
    "有时我们希望既不是上一层的结果，但不更新参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0405, grad_fn=<SumBackward0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand(size = (20,20),requires_grad = False)\n",
    "        self.linear = nn.Linear(20,20)\n",
    "    def forward(self,X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.matmul(X,self.rand_weight))\n",
    "        X = self.linear(X)\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.762945500Z",
     "start_time": "2023-07-31T05:32:32.758485900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 拼接多个组合块"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-0.1530, grad_fn=<SumBackward0>)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20,64),nn.ReLU(),\n",
    "                                 nn.Linear(64,32),nn.ReLU())\n",
    "        self.linear = nn.Linear(32,16)\n",
    "    def forward(self,X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "net = nn.Sequential(NestMLP(),nn.Linear(16,20),FixedHiddenMLP())\n",
    "net(X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.767743600Z",
     "start_time": "2023-07-31T05:32:32.762945500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 参数管理（访问训练后的参数）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.3763],\n        [0.1984]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "X = torch.rand(2,4)\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.771167900Z",
     "start_time": "2023-07-31T05:32:32.767743600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[ 0.3462,  0.1429,  0.0163,  0.2945],\n",
      "        [ 0.2426,  0.3157,  0.2454, -0.0122],\n",
      "        [-0.0865,  0.0528, -0.4299, -0.2637],\n",
      "        [ 0.4305,  0.4042, -0.0057,  0.1168],\n",
      "        [ 0.0675, -0.1138, -0.4166,  0.1081],\n",
      "        [ 0.3368,  0.2728, -0.3628,  0.1518],\n",
      "        [-0.3245,  0.3184, -0.1615, -0.3213],\n",
      "        [-0.2776,  0.0995, -0.1669, -0.2560]])), ('bias', tensor([ 0.0641, -0.4824,  0.3883, -0.2839,  0.2964,  0.2484,  0.2923,  0.2991]))])\n",
      "OrderedDict()\n",
      "OrderedDict([('weight', tensor([[-0.2101, -0.2803,  0.2713, -0.1288,  0.0774,  0.2232,  0.2494, -0.0565]])), ('bias', tensor([0.2680]))])\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([0.2680], requires_grad=True)\n",
      "tensor([0.2680])\n"
     ]
    }
   ],
   "source": [
    "print(net[0].state_dict()) # nn.Linear(4,8)\n",
    "print(net[1].state_dict()) # ReLU\n",
    "print(net[2].state_dict()) # nn.Linear(8,1)\n",
    "\n",
    "print(type(net[2].bias)) # nn.parameter\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.804390600Z",
     "start_time": "2023-07-31T05:32:32.772673400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "source": [
    "print(*[(name,param.shape) for name,param in net.named_parameters()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.804390600Z",
     "start_time": "2023-07-31T05:32:32.776357300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2101, -0.2803,  0.2713, -0.1288,  0.0774,  0.2232,  0.2494, -0.0565]])\n",
      "tensor([0.2680])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict()['2.weight'])\n",
    "print(net.state_dict()['2.bias'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T05:32:32.804390600Z",
     "start_time": "2023-07-31T05:32:32.778893100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "OrderedDict([('0.block0.0.weight', tensor([[-0.3903,  0.4064, -0.1030, -0.4715],\n",
      "        [-0.3094,  0.0719,  0.4342,  0.3138],\n",
      "        [ 0.2928, -0.4540, -0.2056,  0.2434],\n",
      "        [ 0.1601, -0.3681, -0.4981, -0.4812],\n",
      "        [-0.2176,  0.0475, -0.2227,  0.0238],\n",
      "        [ 0.0167, -0.3026,  0.2491,  0.1439],\n",
      "        [-0.1192, -0.1666, -0.3123,  0.1224],\n",
      "        [-0.1189,  0.3075, -0.2857, -0.3253]])), ('0.block0.0.bias', tensor([ 0.0112,  0.3474,  0.2986,  0.0627, -0.4871,  0.2269, -0.3341,  0.3101])), ('0.block0.2.weight', tensor([[-0.2303, -0.0793, -0.2961, -0.3213,  0.1449, -0.2813, -0.0120, -0.2100],\n",
      "        [ 0.1055,  0.0389, -0.1473,  0.2802,  0.2275,  0.1188, -0.2776, -0.1522],\n",
      "        [ 0.0321,  0.0412,  0.1878, -0.3481, -0.3306,  0.0693,  0.3116, -0.3189],\n",
      "        [ 0.3345, -0.1747, -0.3402,  0.2400, -0.1471,  0.1517,  0.0708,  0.2208]])), ('0.block0.2.bias', tensor([-0.3292, -0.2000,  0.2338,  0.0152])), ('0.block1.0.weight', tensor([[ 0.4897, -0.4786, -0.3681,  0.0508],\n",
      "        [-0.4057,  0.3306,  0.1671, -0.1738],\n",
      "        [ 0.2504,  0.4864,  0.3346,  0.2826],\n",
      "        [-0.3534,  0.4355,  0.2734, -0.2140],\n",
      "        [ 0.1484,  0.1509, -0.4615,  0.3672],\n",
      "        [-0.0603,  0.0758,  0.3993,  0.1833],\n",
      "        [-0.1404,  0.3323,  0.1903, -0.4811],\n",
      "        [ 0.2744, -0.0539, -0.2132,  0.3534]])), ('0.block1.0.bias', tensor([ 0.3861,  0.3614,  0.1110, -0.3867, -0.0723, -0.1703,  0.0138, -0.4649])), ('0.block1.2.weight', tensor([[-0.2753,  0.2382, -0.2783,  0.3119, -0.1195, -0.3045,  0.2081,  0.2779],\n",
      "        [ 0.3325,  0.1433,  0.2315,  0.1502, -0.1175, -0.1586,  0.2060, -0.3220],\n",
      "        [-0.1713,  0.0849,  0.1876,  0.1675,  0.3298, -0.1469, -0.1943, -0.1398],\n",
      "        [ 0.2702, -0.1980, -0.2929,  0.2844,  0.3344, -0.0469,  0.2157, -0.2003]])), ('0.block1.2.bias', tensor([-0.2616,  0.0933, -0.2375,  0.3092])), ('0.block2.0.weight', tensor([[-0.4705, -0.0574,  0.4488,  0.0180],\n",
      "        [-0.2735,  0.3444,  0.2682,  0.0254],\n",
      "        [-0.0830, -0.4477, -0.4516, -0.2454],\n",
      "        [-0.4496, -0.0766,  0.0145,  0.0966],\n",
      "        [-0.3304, -0.3174,  0.2785, -0.1337],\n",
      "        [ 0.0158,  0.1904,  0.4935,  0.4965],\n",
      "        [-0.0134,  0.0401,  0.4681,  0.0668],\n",
      "        [-0.3828, -0.3081,  0.1237, -0.0023]])), ('0.block2.0.bias', tensor([-0.1366,  0.1643,  0.2091, -0.3854,  0.1285, -0.3911, -0.4985,  0.1094])), ('0.block2.2.weight', tensor([[-0.0542,  0.2885, -0.1104,  0.2872,  0.1412,  0.1545, -0.0116, -0.1969],\n",
      "        [-0.1327,  0.1994, -0.0387, -0.2369, -0.2745, -0.2575,  0.0441, -0.2581],\n",
      "        [-0.3535,  0.1948, -0.1436, -0.0991, -0.1933,  0.1688,  0.0907, -0.3466],\n",
      "        [ 0.2372,  0.0957, -0.1963, -0.2129,  0.1254, -0.0554,  0.0542,  0.0082]])), ('0.block2.2.bias', tensor([-0.1183,  0.3194,  0.3036,  0.0913])), ('0.block3.0.weight', tensor([[ 0.4284,  0.0145, -0.4862, -0.4983],\n",
      "        [-0.0008, -0.4958, -0.3663, -0.1232],\n",
      "        [ 0.3216, -0.2090,  0.4778,  0.1395],\n",
      "        [-0.4863, -0.4194,  0.2607, -0.2357],\n",
      "        [-0.1986, -0.4881,  0.2226,  0.4461],\n",
      "        [-0.3966,  0.0773, -0.2965,  0.3454],\n",
      "        [-0.4597, -0.2615, -0.2971, -0.4001],\n",
      "        [-0.4329,  0.4594,  0.3431, -0.3217]])), ('0.block3.0.bias', tensor([ 0.0303,  0.1468, -0.4796,  0.2742,  0.4111,  0.4275,  0.0363, -0.4660])), ('0.block3.2.weight', tensor([[-0.2600,  0.3452,  0.1735, -0.0287, -0.1535,  0.2577, -0.2054, -0.0067],\n",
      "        [ 0.0544, -0.2076,  0.3296,  0.0904, -0.0050,  0.3185,  0.1302, -0.0347],\n",
      "        [ 0.3472,  0.1653, -0.2711,  0.3470, -0.2205, -0.2192,  0.1152,  0.2401],\n",
      "        [-0.1109,  0.3180,  0.0128,  0.0295,  0.2010,  0.3279, -0.3510, -0.1993]])), ('0.block3.2.bias', tensor([-0.1896, -0.3036, -0.0111,  0.2011])), ('1.weight', tensor([[ 0.4885, -0.4713,  0.4050, -0.3699]])), ('1.bias', tensor([0.4900]))])\n"
     ]
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,4))\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block{i}',block1()) # 使用add_module添加块可以多传入一个字符串\n",
    "    return net\n",
    "\n",
    "net = nn.Sequential(block2(),nn.Linear(4,1))\n",
    "net(X)\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T06:07:38.344615300Z",
     "start_time": "2023-07-31T06:07:38.339289500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 内置的参数初始化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0048,  0.0107,  0.0003, -0.0148],\n",
      "        [-0.0067, -0.0160,  0.0061, -0.0129],\n",
      "        [ 0.0228,  0.0020,  0.0053,  0.0201],\n",
      "        [-0.0188,  0.0016, -0.0184,  0.0054],\n",
      "        [ 0.0060, -0.0003,  0.0122,  0.0121],\n",
      "        [ 0.0085,  0.0021, -0.0073, -0.0088],\n",
      "        [ 0.0161, -0.0089, -0.0069, -0.0026],\n",
      "        [-0.0066,  0.0007, -0.0111,  0.0016]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "X = torch.rand(2,4)\n",
    "net(X)\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.normal_(m.weight,0,0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "print(net[0].weight.data)\n",
    "print(net[0].bias.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T06:17:55.038487300Z",
     "start_time": "2023-07-31T06:17:55.035124400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.constant_(m.weight,1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)\n",
    "print(net[0].weight.data)\n",
    "print(net[0].bias.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T06:18:05.833367100Z",
     "start_time": "2023-07-31T06:18:05.824871500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2787,  0.2469,  0.5250, -0.5568],\n",
      "        [-0.3217,  0.2586, -0.0198, -0.1410],\n",
      "        [ 0.0334, -0.4799, -0.6248, -0.1607],\n",
      "        [ 0.2892, -0.3281, -0.4636,  0.5669],\n",
      "        [ 0.0501,  0.7030, -0.1168,  0.5477],\n",
      "        [-0.6724, -0.6529,  0.2516, -0.2298],\n",
      "        [ 0.6283, -0.1949,  0.5596,  0.2460],\n",
      "        [ 0.0287,  0.6724,  0.4476, -0.4665]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "def xavier(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net[0].apply(xavier)\n",
    "net[2].apply(init_constant)\n",
    "print(net[0].weight.data)\n",
    "print(net[2].weight.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T06:37:25.873132200Z",
     "start_time": "2023-07-31T06:37:25.861126200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 参数绑定\n",
    "参数相同的层"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2724,  0.1877, -0.1764,  0.1656],\n",
      "        [-0.2817,  0.0061, -0.2304, -0.1595],\n",
      "        [ 0.0167,  0.2272, -0.1183, -0.0085],\n",
      "        [-0.2418, -0.3935,  0.4363,  0.4493],\n",
      "        [-0.2859,  0.2566,  0.1678,  0.1539],\n",
      "        [-0.0493,  0.4679,  0.0570,  0.3276],\n",
      "        [-0.2413,  0.1631, -0.3888,  0.1512],\n",
      "        [ 0.0638, -0.3136,  0.3000, -0.3908]])\n",
      "tensor([[ 2.4051e-01,  1.2590e-01, -2.7689e-01, -1.2919e-01,  2.8693e-02,\n",
      "          6.4387e-02,  3.4751e-01,  8.9035e-03],\n",
      "        [-2.6194e-01, -3.2073e-01, -1.1763e-01, -2.0224e-02,  3.3490e-01,\n",
      "          3.0266e-01, -9.9295e-02, -1.2610e-02],\n",
      "        [-2.0657e-01,  1.7945e-01,  2.7102e-01,  1.9759e-04, -3.9683e-03,\n",
      "         -3.0819e-01,  2.7293e-01, -1.1431e-01],\n",
      "        [-1.4660e-02, -4.4140e-02, -2.8468e-01,  2.7438e-01,  5.1808e-02,\n",
      "         -2.0387e-01, -1.4990e-02, -2.5242e-01],\n",
      "        [-2.7888e-01,  2.8187e-01, -1.4106e-01,  4.0534e-02,  7.0759e-02,\n",
      "         -9.5099e-02,  2.0322e-02, -3.0415e-01],\n",
      "        [-1.0752e-01,  2.3168e-01, -1.1807e-01, -9.2765e-02, -2.4127e-01,\n",
      "         -3.3599e-01, -1.4307e-01,  2.1263e-01],\n",
      "        [-2.5761e-01, -3.1168e-01, -8.9820e-02,  3.0367e-01, -5.5797e-02,\n",
      "          3.0580e-01, -2.4549e-01,  2.8773e-01],\n",
      "        [ 3.0545e-01, -7.1228e-06, -3.0533e-01, -3.4743e-01, -1.6054e-02,\n",
      "         -2.3983e-01, -1.2352e-01,  8.5594e-02]])\n",
      "tensor([[ 2.4051e-01,  1.2590e-01, -2.7689e-01, -1.2919e-01,  2.8693e-02,\n",
      "          6.4387e-02,  3.4751e-01,  8.9035e-03],\n",
      "        [-2.6194e-01, -3.2073e-01, -1.1763e-01, -2.0224e-02,  3.3490e-01,\n",
      "          3.0266e-01, -9.9295e-02, -1.2610e-02],\n",
      "        [-2.0657e-01,  1.7945e-01,  2.7102e-01,  1.9759e-04, -3.9683e-03,\n",
      "         -3.0819e-01,  2.7293e-01, -1.1431e-01],\n",
      "        [-1.4660e-02, -4.4140e-02, -2.8468e-01,  2.7438e-01,  5.1808e-02,\n",
      "         -2.0387e-01, -1.4990e-02, -2.5242e-01],\n",
      "        [-2.7888e-01,  2.8187e-01, -1.4106e-01,  4.0534e-02,  7.0759e-02,\n",
      "         -9.5099e-02,  2.0322e-02, -3.0415e-01],\n",
      "        [-1.0752e-01,  2.3168e-01, -1.1807e-01, -9.2765e-02, -2.4127e-01,\n",
      "         -3.3599e-01, -1.4307e-01,  2.1263e-01],\n",
      "        [-2.5761e-01, -3.1168e-01, -8.9820e-02,  3.0367e-01, -5.5797e-02,\n",
      "          3.0580e-01, -2.4549e-01,  2.8773e-01],\n",
      "        [ 3.0545e-01, -7.1228e-06, -3.0533e-01, -3.4743e-01, -1.6054e-02,\n",
      "         -2.3983e-01, -1.2352e-01,  8.5594e-02]])\n"
     ]
    }
   ],
   "source": [
    "shared = nn.Linear(8,8)\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),shared,nn.ReLU(),shared,nn.ReLU(),nn.Linear(8,1))\n",
    "print(net[0].weight.data)\n",
    "print(net[2].weight.data)\n",
    "print(net[4].weight.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T06:46:20.887885400Z",
     "start_time": "2023-07-31T06:46:20.876372300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
