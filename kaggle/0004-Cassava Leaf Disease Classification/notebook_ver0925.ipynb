{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  PIL import Image\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:33:44.866569200Z",
     "start_time": "2023-09-26T09:33:31.591464800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "INPUT_PATH = '../input/MyModel'\n",
    "TRAIN_CSV_PATH = '../input/cassava-leaf-disease-classification/train.csv'\n",
    "TRAIN_IMAGE_PATH = '../input/cassava-leaf-disease-classification/train_images/'\n",
    "TEST_IMAGE_PATH = '../input/cassava-leaf-disease-classification/test_images/'\n",
    "DEVICES = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "OUT_FEATURES = 5\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 224\n",
    "OPTIMIZER = torch.optim.AdamW"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:34:08.536046900Z",
     "start_time": "2023-09-26T09:34:06.968989800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tr1.损失函数\n",
    "1st solution's loss\n",
    "1. B4: Sigmoid Focal Cross Entropy Loss: is good for class imbalance problems / label smoothing\n",
    "2. ResNeXt50: Cross Entropy Loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid_focal_cross_entropy(y_hat, y_true, alpha=0.25, gamma=2.0):\n",
    "    # label smoothing\n",
    "    def smooth(y, smooth_factor):\n",
    "        assert  len(y.shape) == 2\n",
    "        y *= 1 - smooth_factor\n",
    "        y += smooth_factor / y.shape[1]\n",
    "        return y\n",
    "\n",
    "    smooth_factor = 0.1\n",
    "\n",
    "    if not isinstance(y_true, torch.Tensor):\n",
    "        y_true = torch.tensor(y_true)\n",
    "    if not isinstance(y_hat, torch.Tensor):\n",
    "        y_hat = torch.tensor(y_hat)\n",
    "\n",
    "    y_true = smooth(y_true, smooth_factor)\n",
    "\n",
    "    cross_entropy = F.binary_cross_entropy_with_logits(y_hat, y_true, reduction='none')\n",
    "    p_t = y_true * y_hat + (1 - y_true) * (1 - y_hat)\n",
    "    alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "    modulating_factor = (1.0 - p_t).pow(gamma)\n",
    "\n",
    "    return torch.sum(alpha_t * modulating_factor * cross_entropy, dim=-1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tr2.learning_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lr_tune(epoch, num_epochs=NUM_EPOCHS):\n",
    "    lr_start = 1e-6\n",
    "    lr_max = 2e-4\n",
    "    lr_final = 1e-6\n",
    "    lr_warmup_epoch = 4\n",
    "    lr_sustain_epoch = 0\n",
    "    lr_decay_epoch = num_epochs - lr_warmup_epoch - lr_sustain_epoch - 1\n",
    "\n",
    "    if epoch <= lr_warmup_epoch:\n",
    "        lr = lr_start + (lr_max - lr_start) * (epoch / lr_warmup_epoch) ** 2.5\n",
    "    elif epoch < lr_warmup_epoch + lr_sustain_epoch:\n",
    "        lr = lr_max\n",
    "    else:\n",
    "        epoch_diff = epoch - lr_warmup_epoch - lr_sustain_epoch\n",
    "        decay_factor = (epoch_diff / lr_decay_epoch) * math.pi\n",
    "        decay_factor = (torch.cos(torch.tensor(decay_factor)).numpy() + 1) / 2\n",
    "        lr = lr_final + (lr_max - lr_final) * decay_factor\n",
    "    return lr\n",
    "x = [i for i in range(NUM_EPOCHS)]\n",
    "y = [lr_tune(i) for i in x]\n",
    "plt.plot(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tr3.albumentations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_augs = A.Compose(\n",
    "    [\n",
    "        A.RandomResizedCrop(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(p=0.5),\n",
    "        A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "        A.CoarseDropout(p=0.5),\n",
    "        A.Cutout(p=0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], p=1.0)\n",
    "valid_augs = A.Compose(\n",
    "    [\n",
    "        A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        A.CenterCrop(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        A.Normalize(\n",
    "             mean=[0.485, 0.456, 0.406],\n",
    "             std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:34:14.337538100Z",
     "start_time": "2023-09-26T09:34:14.332625200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# tr4.TTA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_augs = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n",
    "        A.CenterCrop(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n",
    "        A.RandomResizedCrop(IMAGE_SIZE, IMAGE_SIZE, p=1.0)\n",
    "    ], p=1.0),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0)\n",
    "    ], p=1.0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyCassavaLeafDataset(Dataset):\n",
    "    @staticmethod\n",
    "    def generate_index(num_total, ratio):\n",
    "        all_index = [i for i in range(num_total)]\n",
    "        k = ratio * 10\n",
    "        valid_index = np.arange(0, num_total, k)\n",
    "        train_index = [i for i in all_index if i not in valid_index]\n",
    "        return train_index, valid_index\n",
    "\n",
    "    def __init__(self, csv_path=None, images_path=None, transform=None, mode='train', train_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.images_path = images_path\n",
    "        self.data_info = pd.read_csv(csv_path)\n",
    "        self.data_len = self.data_info.shape[0]\n",
    "        if self.mode == 'train':\n",
    "            train_index, _ = MyCassavaLeafDataset.generate_index(self.data_len, train_ratio)\n",
    "            self.image_arr = np.asarray(self.data_info.iloc[train_index, 0])\n",
    "            self.label_arr = np.asarray(self.data_info.iloc[train_index, 1])\n",
    "            self.real_len = len(self.image_arr)\n",
    "        elif self.mode == 'valid':\n",
    "            _, valid_index = MyCassavaLeafDataset.generate_index(self.data_len, train_ratio)\n",
    "            self.image_arr = np.asarray(self.data_info.iloc[valid_index, 0])\n",
    "            self.label_arr = np.asarray(self.data_info.iloc[valid_index, 1])\n",
    "            self.real_len = len(self.image_arr)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode != 'test':\n",
    "            single_image_name = self.image_arr[index]\n",
    "            image = Image.open(os.path.join(self.images_path, single_image_name))\n",
    "            image = np.array(image)\n",
    "            label = self.label_arr[index]\n",
    "            return self.transform(image=image)[\"image\"], label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.real_len"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set = MyCassavaLeafDataset(csv_path=TRAIN_CSV_PATH, images_path=TRAIN_IMAGE_PATH, transform=train_augs, mode='train')\n",
    "my_train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_set = MyCassavaLeafDataset(csv_path=TRAIN_CSV_PATH, images_path=TRAIN_IMAGE_PATH, transform=valid_augs, mode='valid')\n",
    "my_valid_dataloader = torch.utils.data.DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "my_model = torchvision.models.efficientnet_b4(pretrained=True)\n",
    "my_model.classifier[-1] = nn.Linear(my_model.classifier[-1].in_features, OUT_FEATURES)\n",
    "nn.init.xavier_uniform_(my_model.classifier[-1].weight)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T10:06:29.953880400Z",
     "start_time": "2023-09-26T10:06:29.945653900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 定义训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyTrainer:\n",
    "    @staticmethod\n",
    "    def accurate_count(y_hat, y_true):\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "        y_true = y_true.argmax(axis=1)\n",
    "        correct_count = 0\n",
    "        for i in range(len(y_hat)):\n",
    "            if y_hat[i].type(y_true.dtype) == y_true[i]:\n",
    "                correct_count += 1\n",
    "        return float(correct_count)\n",
    "    @staticmethod\n",
    "    def calc_valid_acc(model, valid_dataloader):\n",
    "        model.eval()\n",
    "        device = next(iter(model.parameters())).device\n",
    "        test_num = 0\n",
    "        test_acc_num = 0\n",
    "        for x, y_true in valid_dataloader:\n",
    "            if isinstance(x, list):\n",
    "                x = [x_1.to(device) for x_1 in x]\n",
    "            else:\n",
    "                x = x.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "            test_num += y_true.shape[0]\n",
    "            test_acc_num += MyTrainer.accurate_count(model(x), y_true)\n",
    "        return test_acc_num / test_num\n",
    "\n",
    "    def __init__(self, optimizer, model, criterion, train_dataloader, valid_dataloader, param_group=True, learning_rate=lr_tune, num_epochs=NUM_EPOCHS, devices=DEVICES):\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.devices = devices\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.param_group = param_group\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        train_num = 0\n",
    "        train_acc_num = 0\n",
    "        for batch_idx, (x, y_true) in enumerate(self.train_dataloader):\n",
    "            y_true_tensor = torch.zeros(size=(len(y_true), OUT_FEATURES))\n",
    "            for i in range(len(y_true)):\n",
    "                label = y_true[i]\n",
    "                y_true_tensor[i, label] = 1\n",
    "            y_true = y_true_tensor\n",
    "            x, y_true = x.to(self.devices[0]), y_true.to(self.devices[0])\n",
    "            self.optimizer.zero_grad()\n",
    "            y_hat = self.model(x)\n",
    "            loss = self.criterion(y_hat, y_true)\n",
    "            loss.sum().backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.sum()\n",
    "            train_num += y_true.shape[0]\n",
    "            train_acc_num += MyTrainer.accurate_count(y_hat, y_true)\n",
    "        return total_loss / train_num, train_acc_num / train_num\n",
    "    def train(self):\n",
    "        best_valid_acc = 0\n",
    "        for epoch in range(self.num_epochs):\n",
    "            if self.param_group:\n",
    "                param_1x = [param for name, param in self.model.named_parameters() if\n",
    "                            name not in ['classifier.1.weight', 'classifier.1.bias']]\n",
    "                self.optimizer = self.optimizer([{'params': param_1x},\n",
    "                                   {'params': self.model.classifier[-1].parameters(),\n",
    "                                    'lr': self.learning_rate(epoch) * 10}],\n",
    "                                  lr=self.learning_rate(epoch), weight_decay=0.001)\n",
    "            else:\n",
    "                self.optimizer = self.optimizer(self.model.parameters(), lr=self.learning_rate(epoch), weight_decay=0.001)\n",
    "            self.model = nn.DataParallel(self.model ,device_ids=self.devices).to(self.devices[0])\n",
    "            train_loss, train_acc = MyTrainer.train_epoch(self)\n",
    "            valid_acc = MyTrainer.calc_valid_acc(self.model, self.valid_dataloader)\n",
    "            if valid_acc > best_valid_acc:\n",
    "                torch.save(self.model.state_dict(), os.path.join(INPUT_PATH, 'best_model.pth'))\n",
    "            print(f'epoch{epoch}:train_loss:{train_acc}, train_acc:{train_acc}, valid_acc:{valid_acc}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_criterion = sigmoid_focal_cross_entropy\n",
    "my_trainer = MyTrainer(OPTIMIZER, my_model, my_criterion, my_train_dataloader, my_valid_dataloader)\n",
    "my_trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
