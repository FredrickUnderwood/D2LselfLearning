{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch Notes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c64ad539a778c28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.stack\n",
    "每个tensor的size必须相同，与torch.cat的区别在于，torch.stack形成了新的维度，而torch.cat不形成新的维度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5785efa5d6b6010"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim=0 stack: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "dim=1 stack: tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "c = torch.stack([a, b], dim=0)\n",
    "d = torch.stack([a, b], dim=1)\n",
    "# e = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "# f = torch.stack([a, e], dim=1) Error:stack expects each tensor to be equal size, but got [3] at entry 0 and [2, 3] at entry 1\n",
    "print('dim=0 stack:', c)\n",
    "print('dim=1 stack:', d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:17.283489200Z",
     "start_time": "2024-01-10T01:07:17.241713100Z"
    }
   },
   "id": "4660bd046c0eb6aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.cat\n",
    "在相应dim上进行扩展，别的dim的个数不变"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "610480f640997272"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim=0 cat: tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "dim=1 cat: tensor([[1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 2, 3], [1, 2, 3]])\n",
    "b = torch.cat((a, a), dim=0)\n",
    "c = torch.cat((a, a), dim=1)\n",
    "print('dim=0 cat:', b)\n",
    "print('dim=1 cat:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:17.284489100Z",
     "start_time": "2024-01-10T01:07:17.246082Z"
    }
   },
   "id": "7661a9bc091aa81b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.split\n",
    "torch.split(tensor, split_size_or_sections, dim=0)\n",
    "torch.chunk是比较简单的split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5398e00381dfae1b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[-0.9594, -0.7556],\n",
      "        [-1.6402,  1.5177],\n",
      "        [ 1.8255,  1.6826],\n",
      "        [ 0.4145,  0.4089],\n",
      "        [-0.4216,  0.1295]])\n",
      "b: (tensor([[-0.9594, -0.7556],\n",
      "        [-1.6402,  1.5177]]), tensor([[1.8255, 1.6826],\n",
      "        [0.4145, 0.4089]]), tensor([[-0.4216,  0.1295]]))\n",
      "c: (tensor([[-0.9594, -0.7556]]), tensor([[-1.6402,  1.5177],\n",
      "        [ 1.8255,  1.6826],\n",
      "        [ 0.4145,  0.4089],\n",
      "        [-0.4216,  0.1295]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(size=(5, 2))\n",
    "print('tensor:', a)\n",
    "b = torch.split(a, 2) # 在dim=0上，每两个划一个tensor\n",
    "c = torch.split(a, [1, 4]) # 在dim=0上，按[1, 4]划分tensor\n",
    "print('b:', b)\n",
    "print('c:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:17.286034700Z",
     "start_time": "2024-01-10T01:07:17.250778400Z"
    }
   },
   "id": "ae822860c0f24eb2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.tensor.detach\n",
    "在 PyTorch 中，.detach() 方法的主要作用是将一个变量从当前的计算图中分离出来，阻止未来的计算在这个变量上的操作被记录在图中。这意味着使用 .detach() 方法的变量不会在反向传播过程中更新其梯度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f98d39dac72ea449"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.meshgrid\n",
    "将一组横坐标和一组纵坐标扩展后得以两两组合，相当于笛卡尔积，一般会reshape，方便后续匹配x和y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b6f939cd43c2d6b"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "y: tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "x.reshape: tensor([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4])\n",
      "y.reshape: tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([1, 2, 3])\n",
    "x, y = torch.meshgrid([a, b], indexing='ij')\n",
    "print('x:', x)\n",
    "print('y:', y)\n",
    "print('x.reshape:', x.reshape(-1))\n",
    "print('y.reshape:', y.reshape(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:17.286034700Z",
     "start_time": "2024-01-10T01:07:17.255445100Z"
    }
   },
   "id": "da1d6f5c334007fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.tensor.repeat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbde47e528f7f454"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3])\n",
    "x = 5  # 行上扩展的个数\n",
    "y = 2  # 列上扩展的个数\n",
    "b = a.repeat(x, y)\n",
    "print('b:', b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:17.343267300Z",
     "start_time": "2024-01-10T01:07:17.259475500Z"
    }
   },
   "id": "afbabbca82e3da4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.repeat_interleave \n",
    "交错的重复\n",
    "similar to numpy.repeat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "436fbdd8868bae02"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([1, 1, 2, 2, 3, 3])\n",
      "c: tensor([1, 1, 2, 2, 3, 3])\n",
      "e: tensor([[1, 2],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [3, 4]])\n",
      "f: tensor([[1, 1, 2, 2],\n",
      "        [3, 3, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = a.repeat_interleave(2)\n",
    "c = torch.repeat_interleave(a, 2, dim=0)\n",
    "d = torch.tensor([[1, 2], [3, 4]])\n",
    "e = torch.repeat_interleave(d, 2, dim=0)\n",
    "f = torch.repeat_interleave(d, 2, dim=1)\n",
    "print('b:', b)\n",
    "print('c:', c)\n",
    "print('e:', e)\n",
    "print('f:', f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:17.344267200Z",
     "start_time": "2024-01-10T01:07:17.262237600Z"
    }
   },
   "id": "b7f882e543f67738"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.unsqueeze\n",
    "返回的tensor指定的维度的size为1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18482f6aa4faecb0"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "c: tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n",
      "d: tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 2, 3],[4, 5, 6]])\n",
    "b = torch.unsqueeze(a, dim=0)\n",
    "c = torch.unsqueeze(a, dim=1)\n",
    "d = torch.unsqueeze(a, dim=2)\n",
    "print('b:', b)\n",
    "print('c:', c)\n",
    "print('d:', d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:17.345265Z",
     "start_time": "2024-01-10T01:07:17.267767200Z"
    }
   },
   "id": "5a49a82f6c387aa8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torchvision.read_image\n",
    "将图片通过RGB值读入变量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccb059a1dddb8376"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[Errno 2] No such file or directory: './sample_path'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-f2361f2ac0ad>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'./sample_path'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py\u001B[0m in \u001B[0;36mread_image\u001B[1;34m(path, mode)\u001B[0m\n\u001B[0;32m    256\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_scripting\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_tracing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    257\u001B[0m         \u001B[0m_log_api_usage_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mread_image\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 258\u001B[1;33m     \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    259\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mdecode_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py\u001B[0m in \u001B[0;36mread_file\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_scripting\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_tracing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m         \u001B[0m_log_api_usage_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mread_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m     \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_ops.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    690\u001B[0m         \u001B[1;31m# We save the function ptr as the `op` attribute on\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    691\u001B[0m         \u001B[1;31m# OpOverloadPacket to access it here.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 692\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    693\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    694\u001B[0m     \u001B[1;31m# TODO: use this to make a __dir__\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [Errno 2] No such file or directory: './sample_path'"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "image = torchvision.io.read_image('./sample_path')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:17.346267Z",
     "start_time": "2024-01-10T01:07:17.270423900Z"
    }
   },
   "id": "46fb279670e4e448"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.max\n",
    "torch.max返回的是要求的最大值，而不是最大值的坐标\n",
    "与广播机制"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d479fb83857c42f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2]],\n",
      "\n",
      "        [[4, 2]]])\n",
      "tensor([[0, 5],\n",
      "        [2, 3],\n",
      "        [1, 3]])\n",
      "tensor([[[1, 5],\n",
      "         [2, 3],\n",
      "         [1, 3]],\n",
      "\n",
      "        [[4, 5],\n",
      "         [4, 3],\n",
      "         [4, 3]]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "a = torch.tensor([[1, 2, 3, 4], [4, 2, 3, 1]])\n",
    "b = torch.tensor([[0, 5, 4, 2], [2, 3, 5, 0], [1, 3, 5, 2]])\n",
    "c = torch.max(a[:, None, :2], b[:, :2])  # 需要结果是一个2×3×2的\n",
    "print(a[:, None, :2])  # 2×1×2 \n",
    "print(b[:, :2])  # 3×2\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:32.384986300Z",
     "start_time": "2024-01-10T01:07:32.373259400Z"
    }
   },
   "id": "8ab1aef36049af4b"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[ 0.4272,  1.1686,  0.0894,  1.3237],\n",
      "        [-0.1953, -0.9074,  0.8726,  0.3237],\n",
      "        [ 0.5091,  0.6331,  1.0734, -0.4880]])\n",
      "b: tensor([0.5091, 1.1686, 1.0734, 1.3237])\n",
      "c: tensor([2, 0, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(3, 4)\n",
    "b, c = torch.max(a, 0)  # torch.max(input, dim) dim: the dimension to reduce\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('c:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:23:55.928211200Z",
     "start_time": "2024-01-10T01:23:55.912850700Z"
    }
   },
   "id": "a76721aae122ab0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.argmax\n",
    "返回的是最大值对应的坐标"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abdd601924fec99"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[ 0.2551, -0.4097,  0.2170, -0.3249],\n",
      "        [-0.1741, -0.8483, -0.1259,  0.4450],\n",
      "        [-0.3797, -1.4070, -0.2251, -0.1578],\n",
      "        [-1.3012, -0.3973,  0.7022, -1.3084]])\n",
      "b: tensor([0, 3, 3, 1])\n",
      "c: tensor([0, 3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "a = torch.randn(4, 4)\n",
    "b = torch.argmax(a, dim=0)\n",
    "c = torch.argmax(a, dim=1)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('c:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:34.270431100Z",
     "start_time": "2024-01-10T01:07:34.262130700Z"
    }
   },
   "id": "9299eda8029c353e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.argsort\n",
    "返回排序后的坐标"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "194f6ee9933e3477"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[ 0.9552,  0.7903, -3.0834, -0.6885],\n",
      "        [ 1.1864,  0.7248, -2.1739,  0.6357],\n",
      "        [ 1.9470,  0.8816,  0.0175,  1.7207],\n",
      "        [-0.1591, -1.1799,  1.3074,  0.0632]])\n",
      "b: tensor([[3, 3, 0, 0],\n",
      "        [0, 1, 1, 3],\n",
      "        [1, 0, 2, 1],\n",
      "        [2, 2, 3, 2]])\n",
      "c: tensor([[2, 3, 1, 0],\n",
      "        [2, 3, 1, 0],\n",
      "        [2, 1, 3, 0],\n",
      "        [1, 0, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(4, 4)\n",
    "b = torch.argsort(a, dim=0)\n",
    "c = torch.argsort(a, dim=1)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('c:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:34.942565900Z",
     "start_time": "2024-01-10T01:07:34.928509100Z"
    }
   },
   "id": "669a7875e1001e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.clamp\n",
    "过滤"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d93da831dd7c300b"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([-0.2850,  0.8066, -0.4880,  0.0433, -0.5219])\n",
      "b: tensor([-0.2850,  0.5000, -0.4880,  0.0433, -0.5000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(5)\n",
    "b = torch.clamp(a, min=-0.5, max=0.5)\n",
    "print('a:', a)\n",
    "print('b:', b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-10T01:07:35.458885100Z",
     "start_time": "2024-01-10T01:07:35.430911200Z"
    }
   },
   "id": "762a3861607f0fb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
