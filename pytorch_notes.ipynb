{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch Notes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c64ad539a778c28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.stack\n",
    "每个tensor的size必须相同，与torch.cat的区别在于，torch.stack形成了新的维度，而torch.cat不形成新的维度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5785efa5d6b6010"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim=0 stack: tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "dim=1 stack: tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "c = torch.stack([a, b], dim=0)\n",
    "d = torch.stack([a, b], dim=1)\n",
    "# e = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "# f = torch.stack([a, e], dim=1) Error:stack expects each tensor to be equal size, but got [3] at entry 0 and [2, 3] at entry 1\n",
    "print('dim=0 stack:', c)\n",
    "print('dim=1 stack:', d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:50.301701800Z",
     "start_time": "2024-01-09T15:46:48.717946500Z"
    }
   },
   "id": "4660bd046c0eb6aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.cat\n",
    "在相应dim上进行扩展，别的dim的个数不变"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "610480f640997272"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim=0 cat: tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "dim=1 cat: tensor([[1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 2, 3], [1, 2, 3]])\n",
    "b = torch.cat((a, a), dim=0)\n",
    "c = torch.cat((a, a), dim=1)\n",
    "print('dim=0 cat:', b)\n",
    "print('dim=1 cat:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:50.311346900Z",
     "start_time": "2024-01-09T15:46:50.298701600Z"
    }
   },
   "id": "7661a9bc091aa81b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.split\n",
    "torch.split(tensor, split_size_or_sections, dim=0)\n",
    "torch.chunk是比较简单的split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5398e00381dfae1b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[-0.6227,  0.4135],\n",
      "        [-0.8811, -0.6452],\n",
      "        [-0.0406, -1.4179],\n",
      "        [-0.6849,  0.4633],\n",
      "        [ 0.1775, -0.6136]])\n",
      "b: (tensor([[-0.6227,  0.4135],\n",
      "        [-0.8811, -0.6452]]), tensor([[-0.0406, -1.4179],\n",
      "        [-0.6849,  0.4633]]), tensor([[ 0.1775, -0.6136]]))\n",
      "c: (tensor([[-0.6227,  0.4135]]), tensor([[-0.8811, -0.6452],\n",
      "        [-0.0406, -1.4179],\n",
      "        [-0.6849,  0.4633],\n",
      "        [ 0.1775, -0.6136]]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(size=(5, 2))\n",
    "print('tensor:', a)\n",
    "b = torch.split(a, 2) # 在dim=0上，每两个划一个tensor\n",
    "c = torch.split(a, [1, 4]) # 在dim=0上，按[1, 4]划分tensor\n",
    "print('b:', b)\n",
    "print('c:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:50.316851700Z",
     "start_time": "2024-01-09T15:46:50.305228200Z"
    }
   },
   "id": "ae822860c0f24eb2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.tensor.detach\n",
    "在 PyTorch 中，.detach() 方法的主要作用是将一个变量从当前的计算图中分离出来，阻止未来的计算在这个变量上的操作被记录在图中。这意味着使用 .detach() 方法的变量不会在反向传播过程中更新其梯度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f98d39dac72ea449"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.meshgrid\n",
    "将一组横坐标和一组纵坐标扩展后得以两两组合，相当于笛卡尔积，一般会reshape，方便后续匹配x和y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b6f939cd43c2d6b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "y: tensor([[1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3],\n",
      "        [1, 2, 3]])\n",
      "x.reshape: tensor([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4])\n",
      "y.reshape: tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([1, 2, 3])\n",
    "x, y = torch.meshgrid([a, b], indexing='ij')\n",
    "print('x:', x)\n",
    "print('y:', y)\n",
    "print('x.reshape:', x.reshape(-1))\n",
    "print('y.reshape:', y.reshape(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:50.325782200Z",
     "start_time": "2024-01-09T15:46:50.314851300Z"
    }
   },
   "id": "da1d6f5c334007fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.tensor.repeat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbde47e528f7f454"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3],\n",
      "        [1, 2, 3, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3])\n",
    "x = 5  # 行上扩展的个数\n",
    "y = 2  # 列上扩展的个数\n",
    "b = a.repeat(x, y)\n",
    "print('b:', b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:50.326284300Z",
     "start_time": "2024-01-09T15:46:50.319387900Z"
    }
   },
   "id": "afbabbca82e3da4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.repeat_interleave \n",
    "交错的重复\n",
    "similar to numpy.repeat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "436fbdd8868bae02"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([1, 1, 2, 2, 3, 3])\n",
      "c: tensor([1, 1, 2, 2, 3, 3])\n",
      "e: tensor([[1, 2],\n",
      "        [1, 2],\n",
      "        [3, 4],\n",
      "        [3, 4]])\n",
      "f: tensor([[1, 1, 2, 2],\n",
      "        [3, 3, 4, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = a.repeat_interleave(2)\n",
    "c = torch.repeat_interleave(a, 2, dim=0)\n",
    "d = torch.tensor([[1, 2], [3, 4]])\n",
    "e = torch.repeat_interleave(d, 2, dim=0)\n",
    "f = torch.repeat_interleave(d, 2, dim=1)\n",
    "print('b:', b)\n",
    "print('c:', c)\n",
    "print('e:', e)\n",
    "print('f:', f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:50.327285700Z",
     "start_time": "2024-01-09T15:46:50.322881800Z"
    }
   },
   "id": "b7f882e543f67738"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.unsqueeze\n",
    "返回的tensor指定的维度的size为1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18482f6aa4faecb0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "c: tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n",
      "d: tensor([[[1],\n",
      "         [2],\n",
      "         [3]],\n",
      "\n",
      "        [[4],\n",
      "         [5],\n",
      "         [6]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1, 2, 3],[4, 5, 6]])\n",
    "b = torch.unsqueeze(a, dim=0)\n",
    "c = torch.unsqueeze(a, dim=1)\n",
    "d = torch.unsqueeze(a, dim=2)\n",
    "print('b:', b)\n",
    "print('c:', c)\n",
    "print('d:', d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:50.389219Z",
     "start_time": "2024-01-09T15:46:50.328292600Z"
    }
   },
   "id": "5a49a82f6c387aa8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torchvision.read_image\n",
    "将图片通过RGB值读入变量"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccb059a1dddb8376"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[Errno 2] No such file or directory: './sample_path'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-f2361f2ac0ad>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'./sample_path'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py\u001B[0m in \u001B[0;36mread_image\u001B[1;34m(path, mode)\u001B[0m\n\u001B[0;32m    256\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_scripting\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_tracing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    257\u001B[0m         \u001B[0m_log_api_usage_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mread_image\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 258\u001B[1;33m     \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    259\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mdecode_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    260\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py\u001B[0m in \u001B[0;36mread_file\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_scripting\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjit\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_tracing\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m         \u001B[0m_log_api_usage_once\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mread_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 52\u001B[1;33m     \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_file\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     53\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_ops.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    690\u001B[0m         \u001B[1;31m# We save the function ptr as the `op` attribute on\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    691\u001B[0m         \u001B[1;31m# OpOverloadPacket to access it here.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 692\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_op\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    693\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    694\u001B[0m     \u001B[1;31m# TODO: use this to make a __dir__\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [Errno 2] No such file or directory: './sample_path'"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "image = torchvision.io.read_image('./sample_path')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:51.068848800Z",
     "start_time": "2024-01-09T15:46:50.333050900Z"
    }
   },
   "id": "46fb279670e4e448"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.max\n",
    "torch.max返回的是要求的最大值，而不是最大值的坐标\n",
    "与广播机制"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d479fb83857c42f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch \n",
    "a = torch.tensor([[1, 2, 3, 4], [4, 2, 3, 1]])\n",
    "b = torch.tensor([[0, 5, 4, 2], [2, 3, 5, 0], [1, 3, 5, 2]])\n",
    "c = torch.max(a[:, None, :2], b[:, :2])  # 需要结果是一个2×3×2的\n",
    "print(a[:, None, :2])  # 2×1×2 \n",
    "print(b[:, :2])  # 3×2\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T15:46:51.067847100Z"
    }
   },
   "id": "8ab1aef36049af4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.argmax\n",
    "返回的是最大值对应的坐标"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abdd601924fec99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch \n",
    "a = torch.randn(4, 4)\n",
    "b = torch.argmax(a, dim=0)\n",
    "c = torch.argmax(a, dim=1)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('c:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T15:46:51.069854500Z"
    }
   },
   "id": "9299eda8029c353e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.argsort\n",
    "返回排序后的坐标"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "194f6ee9933e3477"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(4, 4)\n",
    "b = torch.argsort(a, dim=0)\n",
    "c = torch.argsort(a, dim=1)\n",
    "print('a:', a)\n",
    "print('b:', b)\n",
    "print('c:', c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T15:46:51.073365100Z",
     "start_time": "2024-01-09T15:46:51.070853700Z"
    }
   },
   "id": "669a7875e1001e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.clamp\n",
    "过滤"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d93da831dd7c300b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(5)\n",
    "b = torch.clamp(a, min=-0.5, max=0.5)\n",
    "print('a:', a)\n",
    "print('b:', b)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-09T15:46:51.070853700Z"
    }
   },
   "id": "762a3861607f0fb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
